{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import libraries necessary for this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(style=\"ticks\")\n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the Census dataset\n",
    "data = pd.read_csv(\"No_Starts.csv\")\n",
    "\n",
    "# Success - Display the first record\n",
    "display(data.head(n=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change dtypes\n",
    "#data['BOOKING MONTH']=data['BOOKING MONTH'].astype('datetime64[ns]')\n",
    "#data['LOSS MONTH']=data['LOSS MONTH'].astype('datetime64[ns]')\n",
    "#data['OWNER HIRE DATE']=data['OWNER HIRE DATE'].astype('datetime64[ns]')\n",
    "#data['SELLER HIRE DATE']=data['SELLER HIRE DATE'].astype('datetime64[ns]')\n",
    "#data['COMPANY ID']=data['COMPANY ID'].astype('int64')\n",
    "data['SIC']=data['SIC'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more info on the data\n",
    "print(data.shape)\n",
    "print(data.dtypes)\n",
    "print(data.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEIN = data[['COMPANY ID','CLIENT ID']].copy()\n",
    "FEIN.drop_duplicates(subset=['CLIENT ID'],inplace=True)\n",
    "#print(FEIN)\n",
    "FEIN_counts= pd.value_counts(FEIN['COMPANY ID'].values,sort=False)\n",
    "FEIN_counts.to_dict()\n",
    "data['FEINs']=data['COMPANY ID'].map(FEIN_counts)\n",
    "display(data.head(n=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treat null-values\n",
    "data.drop(['COMPANY ID','CLIENT ID','NET NO START','LOSS MONTH','BOOKING KEY','BOOKING MONTH','SELLER HIRE DATE','OWNER HIRE DATE','Incorporated Date','SIC DIVISION','SIC GROUP','DunsNumber','BANK REGION','BANK MARKET','BANK BRAND','No_of_Stores_Franchise__c','RSD','SELLER NAME','PROJECT OWNER'], inplace=True, axis=1)\n",
    "print(data.shape)\n",
    "data_final = data.dropna(axis=0,how='any')\n",
    "print(data_final.shape)\n",
    "data_final.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove null & exclude strings\n",
    "#data_sns=data.drop(['PRODUCT CODE','OPP TYPE','SELLER NAME','SELLER TENURE','RSD','ASVP','WEEK OF CLOSE','PRODUCT NAME','LEAD SOURCE','COMPANY EE','PRIOR PROVIDER','BILLING STATE','SIC','PROJECT TYPE','START FRAME','PROJECT OWNER','Lost'], axis=1)\n",
    "#data_sns=data.select_dtypes(exclude=['object'])\n",
    "#sns.pairplot(data_sns.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre# Split the data into features and target label\n",
    "lost_raw = data_final['Lost']\n",
    "features_raw = data_final.drop(['Lost'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_raw, lost_raw, test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct to fit on training data only\n",
    "# Import sklearn.preprocessing.StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize a scaler, then apply it to the features\n",
    "scaler = MinMaxScaler() # default=(0, 1)\n",
    "numerical = ['OPP DURATION', 'Count_of_Federal_Taxes__c', 'Count_of_SUI_Taxes__c', 'NET SOLD', 'Client Tenure', 'DaysSinceIncorporated', 'OwnerTenure', 'FEINs']\n",
    "\n",
    "X_train_nm = pd.DataFrame(data = X_train)\n",
    "X_train_nm[numerical] = scaler.fit_transform(X_train[numerical])\n",
    "\n",
    "X_test_nm = pd.DataFrame(data = X_test)\n",
    "X_test_nm[numerical] = scaler.fit_transform(X_test[numerical])\n",
    "\n",
    "\n",
    "# Show an example of a record with scaling applied\n",
    "display(X_train_nm.head(n = 2))\n",
    "display(X_test_nm.head(n = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: One-hot encode the 'features_log_minmax_transform' data using pandas.get_dummies()\n",
    "X_train_final = pd.get_dummies(X_train_nm)\n",
    "X_test_final = pd.get_dummies(X_test_nm)\n",
    "\n",
    "# TODO: Encode the 'income_raw' data to numerical values\n",
    "y_train_final = y_train.apply(lambda x: 1 if x == \"NO\" else 0)\n",
    "y_test_final = y_test.apply(lambda x: 1 if x == \"NO\" else 0)\n",
    "\n",
    "# Print the number of features after one-hot encoding\n",
    "encoded_train = list(X_train_final.columns)\n",
    "print(\"{} total features after one-hot encoding.\".format(len(encoded_train)))\n",
    "\n",
    "encoded_test = list(X_test_final.columns)\n",
    "print(\"{} total features after one-hot encoding.\".format(len(encoded_test)))\n",
    "\n",
    "# Uncomment the following line to see the encoded feature names\n",
    "# print encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA to reduce dimesionality\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components =30)\n",
    "train_X = pca.fit_transform(X_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "# X, y = load training data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"classifier accuracy:\", clf.score(X_test, y_test))\n",
    "\n",
    "#regr = RandomForestRegressor()\n",
    "#regr.fit(X_train, y_train[:,1])\n",
    "#print(\"regressor R^2:\", regr.score(X_test, y_test[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
